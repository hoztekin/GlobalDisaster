# =============================================================================
# 03_Model_05_GridAnalysis.py
# (ULTIMATE: Smart Filter + Coordinates + DETAILED CONSOLE REPORT)
# =============================================================================

import os
# Windows Joblib Ã‡akÄ±ÅŸmasÄ±nÄ± Ã–nle
os.environ["LOKY_MAX_CPU_COUNT"] = "1"

import joblib
import warnings
import numpy as np
import pandas as pd
import plotly.express as px
from pathlib import Path
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Ayarlar
warnings.filterwarnings('ignore')
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)

# Path
try:
    PROJECT_ROOT = Path(__file__).resolve().parents[1]
except NameError:
    PROJECT_ROOT = Path(r"D:\Miuul Final Project\GlobalDisaster")

DATA_FILE = PROJECT_ROOT / "data" / "processed" / "disaster_data_final.csv"
MODEL_DIR = PROJECT_ROOT / "models"
REPORT_DIR = PROJECT_ROOT / "reports" / "model_05"

MODEL_DIR.mkdir(parents=True, exist_ok=True)
REPORT_DIR.mkdir(parents=True, exist_ok=True)

print("=" * 100)
print("ğŸŒ MODEL 05: SPATIAL GRID ANALYSIS (FULL REPORT MODE)")
print("=" * 100)

# 1. Veri YÃ¼kle
if not DATA_FILE.exists():
    raise FileNotFoundError(f"âŒ Dosya bulunamadÄ±: {DATA_FILE}")

df = pd.read_csv(DATA_FILE)
print(f"âœ… Ham Veri YÃ¼klendi: {len(df)} satÄ±r")

# 2. Grid OluÅŸturma (2 Derece)
GRID_SIZE = 2.0
df['grid_lat'] = np.floor(df['latitude'] / GRID_SIZE) * GRID_SIZE + (GRID_SIZE / 2)
df['grid_lon'] = np.floor(df['longitude'] / GRID_SIZE) * GRID_SIZE + (GRID_SIZE / 2)
df['grid_id'] = df['grid_lat'].astype(str) + "_" + df['grid_lon'].astype(str)

# 3. Aggregation (Ã–zetleme)
print("\n[1/4] Gridler OluÅŸturuluyor ve Ã–zetleniyor...")
grid_df = df.groupby(['grid_id', 'grid_lat', 'grid_lon']).agg({
    'severity_index': 'mean',
    'economic_loss_usd': 'sum',
    'casualties': 'sum',
    'date': 'count'
}).reset_index()

grid_df.columns = ['grid_id', 'lat', 'lon', 'avg_severity', 'total_loss', 'total_casualties', 'event_count']
print(f"   -> Toplam Ham Grid SayÄ±sÄ±: {len(grid_df)}")

# 4. Risk Skoru ve Filtreleme
print("\n[2/4] Risk Skoru HesaplanÄ±yor ve Ã‡Ã¶p Veriler AtÄ±lÄ±yor...")
grid_df['risk_score'] = (
    (grid_df['avg_severity'] * 0.3) +
    (np.log1p(grid_df['total_loss']) * 0.3) +
    (np.log1p(grid_df['total_casualties']) * 0.3) +
    (np.log1p(grid_df['event_count']) * 0.1)
)

# Filtre: Top %15
threshold = grid_df['risk_score'].quantile(0.85)
filtered_df = grid_df[grid_df['risk_score'] > threshold].copy()

print(f"   -> Risk EÅŸik DeÄŸeri (Threshold): {threshold:.2f}")
print(f"   -> Filtre Ã–ncesi: {len(grid_df)} Grid")
print(f"   -> Filtre SonrasÄ±: {len(filtered_df)} Grid (Sadece Kritik BÃ¶lgeler)")

# 5. Clustering
print("\n[3/4] K-Means KÃ¼meleme ve Model PerformansÄ±...")
X = filtered_df[['risk_score', 'avg_severity']]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
filtered_df['cluster'] = kmeans.fit_predict(X_scaled)

# KÃ¼me Ä°simlendirme
rank = filtered_df.groupby('cluster')['risk_score'].mean().sort_values().index
labels = {rank[0]: 'High Risk', rank[1]: 'Very High Risk', rank[2]: 'Extreme Danger Zone'}
filtered_df['risk_label'] = filtered_df['cluster'].map(labels)

# --- DETAYLI KONSOL RAPORU (GERÄ° GELDÄ°) ---
print("-" * 50)
print("ğŸ“ˆ MODEL Ä°STATÄ°STÄ°KLERÄ°")
print("-" * 50)

# Silhouette Score
score = silhouette_score(X_scaled, filtered_df['cluster'])
print(f"ğŸ”¹ Silhouette Score: {score:.4f} (AyrÄ±ÅŸma Kalitesi)")

# KÃ¼me Profilleri (OkunaklÄ± Tablo)
summary = filtered_df.groupby('risk_label').agg({
    'risk_score': 'mean',
    'avg_severity': 'mean',
    'total_loss': 'mean',
    'total_casualties': 'mean',
    'event_count': 'count'
}).sort_values('risk_score', ascending=False)

# Para birimini okunur yapalÄ±m (Milyon $)
summary['total_loss'] = (summary['total_loss'] / 1e6).map('${:,.1f}M'.format)
summary['total_casualties'] = summary['total_casualties'].map('{:,.0f}'.format)
summary = summary.rename(columns={'event_count': 'grid_count'})

print("\nğŸ”¹ KÃ¼me Profilleri (Ortalamalar):")
print(summary)

print("\nğŸ”¹ Yorum:")
print(f"   ğŸ‘‰ En tehlikeli '{labels[rank[2]]}' grubunda {summary.loc['Extreme Danger Zone', 'grid_count']} adet bÃ¶lge var.")
print(f"   ğŸ‘‰ Bu bÃ¶lgelerdeki ortalama maddi kayÄ±p: {summary.loc['Extreme Danger Zone', 'total_loss']}")

# 6. KayÄ±t
joblib.dump(kmeans, MODEL_DIR / "kmeans_grid_model.pkl")
filtered_df.to_csv(REPORT_DIR / "grid_risk_map_data.csv", index=False)

# 7. GÃ¶rselleÅŸtirme
print("\n[4/4] HTML Harita Raporu HazÄ±rlanÄ±yor (KoordinatlÄ±)...")

fig = px.scatter_geo(
    filtered_df,
    lat="lat",
    lon="lon",
    color="risk_label",
    size="risk_score",
    hover_name="grid_id",
    # KoordinatlarÄ± ve detaylarÄ± gÃ¶steren ayar
    hover_data={
        "lat": ":.2f",
        "lon": ":.2f",
        "total_loss": ":,.0f",
        "total_casualties": ":,.0f",
        "risk_score": ":.2f"
    },
    title=f"ğŸŒ Global Disaster Hotspots (Top 15% Risk) - {len(filtered_df)} Zones Identified",
    projection="natural earth",
    color_discrete_map={
        "High Risk": "#FFA500",         # Turuncu
        "Very High Risk": "#FF4500",    # Koyu Turuncu
        "Extreme Danger Zone": "#8B0000" # Kan KÄ±rmÄ±zÄ±sÄ±
    },
    opacity=0.8
)

fig.update_geos(
    showcoastlines=True, coastlinecolor="#333333",
    showland=True, landcolor="#f4f4f4",
    showocean=True, oceancolor="#eef"
)
fig.update_layout(height=700, margin={"r":0,"t":50,"l":0,"b":0})

out_path = REPORT_DIR / "model_05_grid_map.html"
fig.write_html(out_path)
print(f"âœ… Rapor Kaydedildi: {out_path}")
print("=" * 100)